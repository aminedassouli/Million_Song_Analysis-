{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Million Songs Analysis</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting the Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://host-192-168-1-153-ldsa:7077\")\\\n",
    "        .appName(\"Project_19\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.dynamicAllocation.initialExecutors\", 2)\\\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 2)\\\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", 2)\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import io, time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, when\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data into RDDs (Skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function turns a list of binary elements to a string with the element separated by the character ',' \"\"\"\n",
    "def list_bin_to_str(list_terms) :\n",
    "    string=\"\"\n",
    "    for term in list_terms :\n",
    "        string += term.decode()+','\n",
    "    return string[1:-1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" We prepare first a RDD containing tuples (song_information, artist_information) \"\"\"\n",
    "#rdd = spark_context.binaryFiles(\"hdfs://host-192-168-1-153-ldsa:9000/millionsongs/data/A/B/*\")\n",
    "rdd = spark_context.binaryFiles(\"/mnt/ms/data/A/*/*\")\n",
    "\n",
    "# A function to open the h5 files one by one and take the information of interest for the song and the artist\n",
    "def f(x):\n",
    "    with h5py.File(io.BytesIO(x[1])) as f:\n",
    "        \n",
    "        f_meta = f['metadata'][\"songs\"]\n",
    "        f_analys = f['analysis'][\"songs\"]\n",
    "        f_brainz = f['musicbrainz'][\"songs\"]\n",
    "        \n",
    "        artist_terms = list_bin_to_str(f['metadata']['artist_terms'][:10])\n",
    "        similar_artists = list_bin_to_str(f['metadata']['similar_artists'][:10])\n",
    "        \n",
    "        return ((f_meta[0][-3].decode(), f_meta[0][-2].decode(),\n",
    "                f_meta[0][9].decode(), f_meta[0][4].decode(),\n",
    "                f_meta[0][-6].decode(),\n",
    "                float(f_analys[0][3]), float(f_meta[0][-4]),\n",
    "                float(f_analys[0][2]), float(f_analys[0][23]), \n",
    "                float(f_analys[0][-4]), int(f_brainz[0][1])), \n",
    "               \n",
    "                (f_meta[0][4].decode(), f_meta[0][9].decode(),\n",
    "                f_meta[0][6].decode(), float(f_meta[0][3]),\n",
    "                artist_terms, similar_artists))\n",
    "\n",
    "rdd = rdd.map(f)\n",
    "\n",
    "\"\"\" We create two RDDs (songs, artists) from the general one \"\"\"\n",
    "rdd_songs = rdd.map(lambda x : x[0])\n",
    "rdd_artists = rdd.map(lambda x : x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning RDDs to Data frames (Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Songs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-abb04d086859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdf_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msongs_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "attributes = rdd_songs.map(lambda p: Row(p[0], p[1], p[2], p[3], p[4], p[5], p[6], p[7], p[8], p[9], p[10]))\n",
    "fields = [StructField(\"song_id\", StringType(), True), StructField(\"title\", StringType(), True), \n",
    "          StructField(\"artist_name\", StringType(), True), StructField(\"artist_id\", StringType(), True),\n",
    "          StructField(\"release_album\", StringType(), True), \n",
    "          StructField(\"duration\", FloatType(), True), StructField(\"hotness\", FloatType(), True), \n",
    "          StructField(\"danceability\", FloatType(), True), StructField(\"loudness\", FloatType(), True), \n",
    "          StructField(\"tempo\", FloatType(), True), StructField(\"year\", IntegerType())]\n",
    "songs_schema = StructType(fields)\n",
    "\n",
    "df_songs = spark_session.createDataFrame(attributes, songs_schema)\n",
    "df_songs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Artists </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = rdd_artists.map(lambda p: Row(p[0], p[1], p[2], p[3], p[4], p[5]))\n",
    "fields = [StructField(\"id\", StringType(), True), StructField(\"name\", StringType(), True), \n",
    "          StructField(\"location\", StringType(), True), StructField(\"hotness\", FloatType(), True),\n",
    "          StructField(\"terms\", StringType(), True), \n",
    "          StructField(\"similar_artists\", StringType(), True)]\n",
    "artists_schema = StructType(fields)\n",
    "\n",
    "df_artists = spark_session.createDataFrame(attributes, artists_schema)\\\n",
    "                          .dropDuplicates()\n",
    "df_artists.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data frames in csv files (Skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Songs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs.write.format('com.databricks.spark.csv')\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save('/home/ubuntu/MySongs_all.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Artists </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists.write.format('com.databricks.spark.csv')\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .save('/home/ubuntu/MyArtists_all.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data frames from csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Songs </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [StructField(\"song_id\", StringType(), True), StructField(\"title\", StringType(), True), \n",
    "          StructField(\"artist_name\", StringType(), True), StructField(\"artist_id\", StringType(), True),\n",
    "          StructField(\"release_album\", StringType(), True), \n",
    "          StructField(\"duration\", FloatType(), True), StructField(\"hotness\", FloatType(), True), \n",
    "          StructField(\"danceability\", FloatType(), True), StructField(\"loudness\", FloatType(), True), \n",
    "          StructField(\"tempo\", FloatType(), True), StructField(\"year\", IntegerType())]\n",
    "songs_schema = StructType(fields)\n",
    "\n",
    "\n",
    "\n",
    "df_songs = spark_session.read\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .csv('hdfs://192.168.1.153:50070/team19/MySongs.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the table : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- song_id: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_name: string (nullable = true)\n",
      " |-- artist_id: string (nullable = true)\n",
      " |-- release_album: string (nullable = true)\n",
      " |-- duration: float (nullable = true)\n",
      " |-- hotness: float (nullable = true)\n",
      " |-- danceability: float (nullable = true)\n",
      " |-- loudness: float (nullable = true)\n",
      " |-- tempo: float (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o206.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 25, 192.168.1.19, executor 1): java.io.FileNotFoundException: File file:/home/ubuntu/MySongs_all.csv/part-00014-7332750c-3232-4c44-9c20-cb4e3cc476db-c000.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:132)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:125)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1165)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:274)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: File file:/home/ubuntu/MySongs_all.csv/part-00014-7332750c-3232-4c44-9c20-cb4e3cc476db-c000.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:132)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:125)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1165)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-139562cb7d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \"\"\"\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python3.6/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o206.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 25, 192.168.1.19, executor 1): java.io.FileNotFoundException: File file:/home/ubuntu/MySongs_all.csv/part-00014-7332750c-3232-4c44-9c20-cb4e3cc476db-c000.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:132)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:125)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1165)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:1889)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:1877)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:1876)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:926)\n\tat scala.Option.foreach(Option.scala:274)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2061)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2082)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2101)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:365)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3383)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$2(Dataset.scala:3364)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:78)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:73)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3364)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2544)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2758)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:254)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:291)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.io.FileNotFoundException: File file:/home/ubuntu/MySongs_all.csv/part-00014-7332750c-3232-4c44-9c20-cb4e3cc476db-c000.csv does not exist\nIt is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.org$apache$spark$sql$execution$datasources$FileScanRDD$$anon$$readCurrentFile(FileScanRDD.scala:132)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.nextIterator(FileScanRDD.scala:177)\n\tat org.apache.spark.sql.execution.datasources.FileScanRDD$$anon$1.hasNext(FileScanRDD.scala:101)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:636)\n\tat org.apache.spark.sql.execution.columnar.CachedRDDBuilder$$anon$1.hasNext(InMemoryRelation.scala:125)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:221)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:299)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1165)\n\tat org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:1091)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1156)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:882)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:335)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:286)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:288)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:121)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:411)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "df_songs.printSchema()\n",
    "df_songs.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> *   Table Artists </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [StructField(\"id\", StringType(), True), StructField(\"name\", StringType(), True), \n",
    "          StructField(\"location\", StringType(), True), StructField(\"hotness\", FloatType(), True),\n",
    "          StructField(\"terms\", StringType(), True), \n",
    "          StructField(\"similar_artists\", StringType(), True)]\n",
    "artists_schema = StructType(fields)\n",
    "\n",
    "df_artists = spark_session.read.load('file:/home/ubuntu/MyArtists.csv', \n",
    "                          format='com.databricks.spark.csv', \n",
    "                          header='true', \n",
    "                          schema=artists_schema)\\\n",
    "                          .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at this table as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- hotness: float (nullable = true)\n",
      " |-- terms: string (nullable = true)\n",
      " |-- similar_artists: string (nullable = true)\n",
      "\n",
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "|                id|                name|            location|   hotness|               terms|     similar_artists|\n",
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "|ARM41VP1187FB52F30|     The Five Satins|       New Haven, CT|0.42246866|oo-wop,soft rock,...|R5MJOG1187FB382DF...|\n",
      "|AR4DHNI1187FB36871|       Alfred Newman|       New Haven, CT|0.31283298|azz,soundtrack,ea...|RKU15L1187B99198D...|\n",
      "|ARRH7LQ1187B9B4A77|Michael Allen Har...|       United States|0.35435557|asy listening,coo...|R5N6X41187B988BFF...|\n",
      "|ARYWF8L1187B98A016|              Zumjay|                null| 0.3239861|ancehall,reggae,j...|RX9I2Y1187FB4B5EB...|\n",
      "|ARV2MS01187FB39026|          Les Baxter|         Detroit, MI|0.41340813|asy listening,lat...|R0O9WU1187FB55E83...|\n",
      "|ARPN2BY1187B999693|       Mind.In.A.Box|                null|0.43679497|uturepop,dark wav...|R8YYNB1187B9A4BB3...|\n",
      "|ARA04401187B991E6E|JOSEF LOCKE & ORC...|Londonderry, Nort...| 0.2859012|olk rock,folk,cou...|RKLWV31187FB4881F...|\n",
      "|ARHJMXS1187FB464C8|   Between The Trees|         Orlando, FL| 0.4915116|iano rock,emo,mod...|RYK3341187B98BE06...|\n",
      "|AR6HPLV1187FB4A1BC|      Sample Rippers|                null| 0.3675651|ard trance,hardst...|RIMMYT1269FCD4C88...|\n",
      "|ARW24PI1187B9A6126|               Jewel|          Payson, UT|0.50952834|op rock,rock,pop,...|RH5FJJ1187FB3F787...|\n",
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artists.printSchema()\n",
    "df_artists.limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the song information in a visible way (as a string) \"\"\"\n",
    "def song_str(song) :\n",
    "    if song[\"year\"] != 0 :\n",
    "        return \"{} - {} ({})\".format(song[\"title\"], song[\"artist_name\"], song[\"year\"])\n",
    "    else :\n",
    "        return \"{} - {}\".format(song[\"title\"], song[\"artist_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function asks the user for the title of a song and returns it from the database \"\"\"\n",
    "def ask_for_song() :\n",
    "    right = False # Boolean to verify that the user's song is the one found in the database   \n",
    "    while not right : \n",
    "        song_title = input(\" Title of the song : \")\n",
    "        # We look at the song in the database even if the user enters an incomplete name\n",
    "        song = df_songs.filter(df_songs[\"title\"].like(\"%\" + song_title + \"%\")).first()\n",
    "        while song == None :\n",
    "            print(\" This song doesn't exist in the database\")\n",
    "            song = df_songs.filter(df_songs[\"title\"].like(\"%\" + input(\"Title of the song : \") + \"%\")).first()\n",
    "        right = (input(\" Is your song {} (y/n) ? \".format(song_str(song))) == 'y')\n",
    "    \n",
    "    print(\" The chosen song is : {} \".format(song_str(song)))\n",
    "    return song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs which belong to the same artist as the input song(Row) \"\"\"\n",
    "def same_artist(song) :\n",
    "    similar_songs = df_songs.filter(df_songs.artist_name == song[\"artist_name\"])\n",
    "    return similar_songs.filter(similar_songs.title != song[\"title\"])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs, from the dataframe, which have similar tempo as the input song\"\"\"\n",
    "def similar_tempo(song, dataframe, margin) : \n",
    "    similar_songs = dataframe.filter(dataframe.tempo.between(song[\"tempo\"] - margin, song[\"tempo\"] + margin))\\\n",
    "                             .filter(dataframe.title != song[\"title\"])\n",
    " \n",
    "    return similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs, from the dataframe, which have similar loudness as the input song \"\"\"\n",
    "def similar_loudness(song, dataframe, margin) : \n",
    "    similar_songs = dataframe.filter(dataframe.loudness.between(song[\"loudness\"] - margin, song[\"loudness\"] + margin))\\\n",
    "                             .filter(dataframe.title != song[\"title\"])\n",
    "\n",
    "    return similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs, from the dataframe, which have similar hotness as the input song \"\"\"\n",
    "def similar_hotness(song, dataframe, margin) : \n",
    "    similar_songs = dataframe.filter(dataframe.hotness.between(song[\"hotness\"] - margin, song[\"hotness\"] + margin))\\\n",
    "                             .filter(dataframe.title != song[\"title\"])\n",
    "\n",
    "    return similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs, from the dataframe, which have similar danceability as the input song \"\"\"\n",
    "def similar_danceability(song, dataframe, margin) : \n",
    "    similar_songs = dataframe.filter(dataframe.danceability.between(song[\"danceability\"] - margin, song[\"danceability\"] + margin))\\\n",
    "                             .filter(dataframe.title != song[\"title\"])\n",
    "\n",
    "    return similar_songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function returns the songs, from the dataframe, which are similar to the input song based on tempo, loudness,\n",
    "hotness and danceability \"\"\"\n",
    "# number is the number of generated suggestions\n",
    "# margins is a dictionary with the 4 attributes above as keys and their corresponding values are a tuple of\n",
    "# (initial margin, margin_increase)\n",
    "def similar_model1(song, number, margins) :\n",
    "    similar_songs = spark_session.createDataFrame(spark_context.emptyRDD(), songs_schema)\n",
    "    x = 0\n",
    "    while similar_songs.count() < number :\n",
    "        similar_songs_inter = similar_tempo(song, df_songs, margins[\"tempo\"][1] * x + margins[\"tempo\"][0])\n",
    "        similar_songs_inter = similar_loudness(song, similar_songs_inter, margins[\"loudness\"][1] * x + margins[\"loudness\"][0])\n",
    "        similar_songs_inter = similar_danceability(song, similar_songs_inter, margins[\"hotness\"][1] * x + margins[\"hotness\"][0])\n",
    "        similar_songs = similar_hotness(song, similar_songs_inter, margins[\"danceability\"][1] * x + margins[\"danceability\"][0])\n",
    "        x += 1\n",
    "    return similar_songs.limit(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking the user for a song "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Title of the song : z\n",
      " Is your song Born In The Famine feat. Sizzla & Jesse Jendah - Luciano (y/n) ? n\n",
      " Title of the song : re\n",
      " Is your song The Creatures Are Having Fun ... - Murder At The Registry (2003) (y/n) ? y\n",
      " The chosen song is : The Creatures Are Having Fun ... - Murder At The Registry (2003) \n"
     ]
    }
   ],
   "source": [
    "user_song = ask_for_song()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs from the same artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This artist doesn't have any other songs.\n"
     ]
    }
   ],
   "source": [
    "songs_same_artist = same_artist(user_song)\n",
    "if songs_same_artist.count() != 0 :\n",
    "    some_songs = songs_same_artist.take(10)\n",
    "    print(\" Songs from the same artist :\")\n",
    "    for song in some_songs : \n",
    "        print(\" * \", song[\"title\"])\n",
    "else :\n",
    "    print(\" This artist doesn't have any other songs.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs with similar tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs with similar tempo (with a margin of 10) :\n",
      " * The Blessing - Joi\n",
      " * Torturing My Soul - Magic Sam\n",
      " * Little Bitty Pretty One - Dee Clark\n",
      " * Born In The Famine feat. Sizzla & Jesse Jendah - Luciano\n",
      " * The Fisherman - Rachael McShane (2009)\n",
      " * ILL 04 - I.L.L.\n",
      " * Love Me Now (Rockwilder Remix) (Feat. Wyclef And Redman) - Beenie Man Featuring Wyclef And Redman\n",
      " * Volcn - KALIMBA (2009)\n",
      " * Sisterhood of Convoluted Thinkers (Piano 2 Remix) - Sisterhood of Convoluted Thinkers\n",
      " * I'll Never Dream - Kaskade (2008)\n"
     ]
    }
   ],
   "source": [
    "margin = 10\n",
    "songs_similar_tempo = similar_tempo(user_song, df_songs, margin).limit(10).collect()\n",
    "if songs_similar_tempo != None :\n",
    "    print(\"Songs with similar tempo (with a margin of {}) :\".format(margin))\n",
    "    for song in songs_similar_tempo : \n",
    "        print(\" * \", end=\"\")\n",
    "        print(song_str(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs with similar loudness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs with similar loudness (with a margin of 0.1) :\n",
      " * Love Has Passed Away - The Supernaturals (1997)\n",
      " * Over To You - Black Sabbath (1978)\n",
      " * Only Do for Love - Cache Cache\n",
      " * Satellites - The Bats\n",
      " * The Sound Of Goodbye (Above & Beyond Vocal Mix) - Perpetuous Dreamer (2001)\n",
      " * Over Now - Lemonator (1997)\n",
      " * 100_000 thoughts - Tap Tap (2006)\n",
      " * Tumba Tumba - Charanga Forever (2000)\n",
      " * The Manageress - Grammatics\n",
      " * Possession - Kim Waters\n"
     ]
    }
   ],
   "source": [
    "margin = 0.1\n",
    "songs_similar_loudness = similar_loudness(user_song, df_songs, margin).limit(10).collect()\n",
    "if songs_similar_loudness != None :\n",
    "    print(\"Songs with similar loudness (with a margin of {}) :\".format(margin))\n",
    "    for song in songs_similar_loudness : \n",
    "        print(\" * \", end=\"\")\n",
    "        print(song_str(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs with similar hotness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs with similar hotness (with a margin of 0.1) :\n",
      " * Fast Girls - The Kingbees (1980)\n",
      " * Our Day Will Come - Angelic Upstarts (1987)\n",
      " * (There'll Be) Peace On The Valley (For Me) - Elvis Presley\n",
      " * Paginas Muertas - Original - Olimpo Cardenas\n",
      " * Come See About Me - Shakin' Stevens (2007)\n",
      " * Little Bitty Pretty One - Dee Clark\n",
      " * My Romance - Bill Evans Trio (1961)\n",
      " * Una Foto En Blanco Y Negro - El Canto del Loco (2003)\n",
      " * Born In The Famine feat. Sizzla & Jesse Jendah - Luciano\n",
      " * Touching Ground (Prognosis) - Frozen Plasma (2008)\n"
     ]
    }
   ],
   "source": [
    "margin = 0.1\n",
    "songs_similar_hotness = similar_hotness(user_song, df_songs, margin).limit(10).collect()\n",
    "if songs_similar_hotness != None :\n",
    "    print(\"Songs with similar hotness (with a margin of {}) :\".format(margin))\n",
    "    for song in songs_similar_hotness : \n",
    "        print(\" * \", end=\"\")\n",
    "        print(song_str(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs with similar danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Songs with similar danceability (with a margin of 0.1) :\n",
      " * Girl Of Mysterious Sorrow (LP Version) - MARC COHN (1998)\n",
      " * The Cookie Bakers of the Night - Laurie Berkner (2001)\n",
      " * Shooting Stars - Cauterize (2003)\n",
      " * The Blessing - Joi\n",
      " * Sappy Love Song - Buck-O-Nine (1994)\n",
      " * Forgotten - Callenish Circle (1999)\n",
      " * Fast Girls - The Kingbees (1980)\n",
      " * Our Day Will Come - Angelic Upstarts (1987)\n",
      " * The Story - Tristan Prettyman (2005)\n",
      " * Falstaff - The Watts Prophets (2005)\n"
     ]
    }
   ],
   "source": [
    "margin = 0.1\n",
    "songs_similar_danceability = similar_danceability(user_song, df_songs, margin).limit(10).collect()\n",
    "if songs_similar_danceability != None :\n",
    "    print(\"Songs with similar danceability (with a margin of {}) :\".format(margin))\n",
    "    for song in songs_similar_danceability : \n",
    "        print(\" * \", end=\"\")\n",
    "        print(song_str(song))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs with similar tempo, loudness, hotness and danceability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = {\"tempo\" : (1, 0.1), \"loudness\" : (1, 0.2), \"hotness\" : (1, 0.3), \"danceability\" : (0.01, 0.02)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things clearer, lets plot first the margins,  which are going to be passed as an argument to the function below, as a function of the number of iterations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD7CAYAAABDld6xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deVxVdfrA8c+XHRFwQQVUFHdQFhE1t9xyS9O0skxnsqasqcxyaqaZXzVWU9OCS5alZWqLqWllWrabY6sKCqiIG2GiICLKvt77/f1xrogGispdgOf9evm6wD333uceLo/f8z3P+T5Ka40QQgjH5WTvAIQQQlycJGohhHBwkqiFEMLBSaIWQggHJ4laCCEcnCRqIYRwcJdM1Eqprkqp+Er/cpVSD9siOCGEEKAup45aKeUMHAP6aq2PWC0qIYQQFVwuc/vhwOFLJWk/Pz/dvn37Kw5KCCEamri4uCytdYuq7rvcRH0bsKqqO5RSM4AZAEFBQcTGxl7mUwshRMOllKp2AFzjk4lKKTdgPLC2qvu11m9qraO11tEtWlT5n4IQQogrcDlVH2OAnVrrE9YKRgghxB9dTqKeQjXTHkIIIaynRnPUSikvYARw75W+UFlZGWlpaRQXF1/pU4ir4OHhQZs2bXB1dbV3KEKIy1SjRK21LgCaX80LpaWl4e3tTfv27VFKXc1TicuktebUqVOkpaURHBxs73CEEJfJZlcmFhcX07x5c0nSdqCUonnz5nI0I0QdZdNLyCVJ24/seyHqLlnrQwghasG29G0s27PMKs/dYBL1mTNneP311+0dhhCinjl85jAPfPcAd399N2v3r6WovKjWX0MStRBCXIGsoiye+eUZJm2YxK4Tu3ik1yOsv3E9ni6etf5aDSZRP/744xw+fJjIyEgee+wxXn75ZXr37k14eDj//ve/AUhNTaVbt25Mnz6dLl26MHXqVL799lsGDBhA586d2b59OwBz5szhT3/6E/369aNz58689dZbgFFd8dhjj9GjRw/CwsJYs2aN3d6vEMI6CssKWZywmOs/vp5PDn7ClG5T+HzS59zV4y7cnd2t8pqXu9ZHrXh6416SjufW6nOGBvrw7xu6V3v/Cy+8wJ49e4iPj+frr79m3bp1bN++Ha0148ePZ+vWrQQFBXHo0CHWrl3LsmXL6N27Nx988AE//vgjGzZs4Pnnn2f9+vUAJCYm8uuvv1JQUEDPnj0ZO3Ysv/zyC/Hx8SQkJJCVlUXv3r259tprCQgIqNX3KoSwPZPZxIbDG3ht12tkFmUyot0IZkXNop1PO6u/tl0Stb19/fXXfP311/Ts2ROA/Px8Dh48SFBQEMHBwYSFhQHQvXt3hg8fjlKKsLAwUlNTK55jwoQJeHp64unpydChQ9m+fTs//vgjU6ZMwdnZmVatWjF48GB27NjB+PHj7fE2hRC15OdjPxMTF8PB0wcJ9wsnZkgMPVv2tNnr2yVRX2zkawtaa/75z39y773nX2iZmpqKu/u5QxcnJ6eK752cnCgvL6+478JyNyl/E6L+2Z+9n3lx8/j5+M+0btyamMExjGw30uZ/7w1mjtrb25u8vDwARo0axbJly8jPzwfg2LFjZGZmXtbzffrppxQXF3Pq1Cm2bNlC7969GTRoEGvWrMFkMnHy5Em2bt1Knz59av29CCGs60TBCZ766Slu2XgLe7L28Fj0Y2y4cQOj2o+yy6CswUx9NG/enAEDBtCjRw/GjBnD7bffTr9+/QBo3Lgx77//Ps7OzjV+vvDwcIYOHUpWVhZPPvkkgYGBTJw4kV9++YWIiAiUUrz00kv4+/tb6y0JIWpZQVkBy/cs552972DSJv4c+mfuCb8HX3dfu8Z1Wa24aio6Olpf2Dhg3759hISE1Ppr2cOcOXNo3Lgxjz76qL1DuSz16XcgRG0qN5fz8cGPeT3+dU4Vn2J0+9E8FPUQbb3b2iwGpVSc1jq6qvsazIhaCCEupLXmh2M/MDd2Lik5KUS1jGLhsIWEtwi3d2jnkUR9BebMmWPvEIQQVynpVBJzY+eyPWM77XzaMX/IfIYHDXfIwgBJ1EKIBiU9P51Xd73KxpSNNHFvwj/7/JNbut6Cq5PjrtUuiVoI0SDklebx9u63eS/pPQD+0uMv/CXsL3i7eds5skuTRC2EqNfKzGWs3b+WxQmLOV1ymnEdxjGz50wCGwfaO7Qak0QthKiXtNZsPrqZBXELSM1NpY9/H2ZHz6Z7c/tecHclGswFL2DUS9eGLVu2MG7cuFp5LiFE7Us8mcj0L6fz8PcP46ScWDR8EUtHLq2TSRpkRC2EqEfS8tJYuHMhX6R+QTOPZjx5zZNM6jwJF6e6neoa1Ij6rOqWI71wpPzggw+yYsUKAL788ku6detGVFQUH3/8ccU2c+bM4a677mLIkCF06NCBhQsXVtz3/vvv06dPHyIjI7n33nsxmUyYTCamT59e8drz588HYOHChYSGhhIeHs5tt91mg70gRP2RU5JDzI4Yxq8fz/dHv+fe8HvZNGkTk7tOrvNJGmo4olZKNQGWAj0ADdyltf7lil/1i8chY/cVP7xK/mEw5oUabfrxxx9XuRxpdYqLi7nnnnvYvHkznTp14tZbbz3v/uTkZL7//nvy8vLo2rUrf/3rXzl06BBr1qzhp59+wtXVlfvvv5+VK1fSvXt3jh07xp49ewCjoQEYy7D+9ttvuLu7V/xMCHFxpaZSVievZkniEvJK85jQaQIPRj5IK69W9g6tVtV0RP0K8KXWuhsQAeyzXkjWV91ypNVJTk4mODiYzp07o5Ri2rRp590/duxY3N3d8fPzo2XLlpw4cYLvvvuOuLg4evfuTWRkJN999x0pKSl06NCBlJQUZs6cyZdffomPjw9grB0ydepU3n//fVxc6v4IQAhr0lrzVepXTFg/gZdjX6aHXw/W3rCWZwc8W++SNNRgRK2U8gWuBaYDaK1LgdKretUajnxtzcXFBbPZXPF9cXFxjR5XeWlUZ2dnysvL0Vpzxx138N///vcP2yckJPDVV1+xePFiPvzwQ5YtW8bnn3/O1q1b2bhxI8899xy7d++WhC1EFXZl7iImNobEk4l0btqZxdctZkDrAfYOy6pqMqIOBk4Cy5VSu5RSS5VSXhdupJSaoZSKVUrFnjx5stYDrU3VLUfarl07kpKSKCkp4cyZM3z33XcAdOvWjdTUVA4fPgzAqlWrLvkaw4cPZ926dRXLp2ZnZ3PkyBGysrIwm83cdNNN/Oc//2Hnzp2YzWaOHj3K0KFDefHFF8nJyalYglUIYTiSe4RHvn+EP3/xZ9Lz03mm/zOsHbe23idpqNkctQsQBczUWm9TSr0CPA48WXkjrfWbwJtgrJ5X24HWpostRzp58mR69OhBcHBwRQcYDw8P3nzzTcaOHUujRo0YNGhQxdrW1QkNDeU///kPI0eOxGw24+rqyqJFi/D09OTOO++sGLn/97//xWQyMW3aNHJyctBa89BDD9GkSRPr7gQh6ojTxadZkriENclrcHV25YHIB/hz6J9p5NrI3qHZzCWXOVVK+QO/aq3bW74fBDyutR5b3WPq+zKndZX8DkRdUmIqYeW+lSxNXEpBeQE3db6J+yPvx8/Tz96hWcVVLXOqtc5QSh1VSnXVWu8HhgNJtR2kEEIAmLWZTb9tYuHOhaQXpHNtm2uZ3Ws2HZt0tHdodlPTs1UzgZVKKTcgBbjTeiEJIRqqHRk7iImNIelUEiHNQnh2wLP0Dehr77DsrkaJWmsdD1Q5JBdCiKuVciaF+XHz2ZK2BX8vf54f+DxjO4zFSTXIa/L+QOq/hBB2k1WUxRvxb/DRwY/wcPFgVtQspoVMw8PFw96hORRJ1EIImysqL+K9pPd4e/fblJpKmdx1MvdF3Eczj2b2Ds0hSaIWQtiMyWxiY8pGXt31KpmFmQwPGs7DUQ/T3re9vUNzaA1mAig1NZUePXrUePsVK1Zw/PhxK0YkRMPyy/FfuPWzW3nypydp6dmSFaNXsGDoAknSNSAj6mqsWLGCHj16EBhYd7pACOGIDp4+yNy4ufx07CdaN27NS9e+xKj2o+RE4WVoUHvKZDJxzz330L17d0aOHElRURHx8fFcc801hIeHM3HiRE6fPs26deuIjY1l6tSpREZGUlRURPv27fn3v/9NVFQUYWFhJCcnA1BQUMBdd91Fnz596NmzJ59++ikAe/furVjiNDw8nIMHD1JQUMDYsWOJiIigR48eFcurClEfnSw8yZyf53DzxptJPJnIo9GPsuHGDYwJHiNJ+jLZZUT94vYXSc5OrtXn7NasG//o84+LbnPw4EFWrVrFW2+9xeTJk/noo4946aWXePXVVxk8eDBPPfUUTz/9NAsWLOC1114jJiaG6OhzVYl+fn7s3LmT119/nZiYGJYuXcpzzz3HsGHDWLZsGWfOnKFPnz5cd911LF68mFmzZjF16lRKS0sxmUxs2rSJwMBAPv/8cwBycnJqdR8I4QgKywpZsXcFK/auoMxcxtSQqcwIm0ETD1kW4Uo1qP/WgoODiYyMBKBXr14cPnyYM2fOMHjwYADuuOMOtm7dWu3jJ02aVPHY1NRUAL7++mteeOEFIiMjGTJkCMXFxfz+++/069eP559/nhdffJEjR47g6elJWFgY33zzDf/4xz/44Ycf8PX1te4bFsKGys3lrDuwjrGfjOWNhDcY1HoQGyZs4O+9/y5J+irZZUR9qZGvtVy4HOnlLtB/9vFnlzIFY13cjz76iK5du563bUhICH379uXzzz/n+uuvZ8mSJQwbNoydO3eyadMmnnjiCYYPH85TTz11le9KCPvSWvPjsR+ZFzePQ2cOEdkikvlD5hPZMtLeodUbDWpEfSFfX1+aNm3KDz/8AMB7771XMbr29va+5Ap5AKNGjeLVV1/l7OJWu3btAqhoEvDQQw8xYcIEEhMTOX78OI0aNWLatGk89thj7Ny500rvTAjbSM5O5p5v7uH+7+6n1FTKvCHzeHfMu5Kka1mDr/p45513uO+++ygsLKRDhw4sX74cgOnTp3Pffffh6enJL79U33XsySef5OGHHyY8PByz2UxwcDCfffYZH374Ie+99x6urq74+/vzr3/9ix07dvDYY4/h5OSEq6srb7zxhq3ephC1KqMgg1d3vcrGwxvxcffh8T6PM7nLZFydXe0dWr10yWVOr4Qsc+qY5HcgrlZ+aT7L9izj3aR30VozNXQqd4fdjY+bj71Dq/OuaplTIYQoM5fx8YGPeT3hdbKLs7k++HoeinqI1o1b2zu0BkEStRCiWlprthzdwry4eaTmphLdKprXh79Od7/u9g6tQZFELYSo0t6svcTExhB7Ipb2Pu1ZOHQhQ9oOQSll79AaHEnUQojzHMs/xsKdC9n02yaaeTTjib5PMKnLJFyd5EShvUiiFkIAkFuay9LdS1mZtBKlFPeE3cNdPe6isVtje4fW4EmiFqKBKzOV8eGBD1mcsJickhxu6HgDM3vOxN/L396hCYsGe8HLnDlziImJcbjXP378ODfffDMAW7ZsYdy4cQBs2LCBF154AYD169eTlCT9hcXV0VrzzZFvuPHTG3lh+wt0bdaVNePW8NzA5yRJOxgZUTuYwMBA1q1b94efjx8/nvHjxwNGoh43bhyhoaG2Dk/UEwknE4jZEUP8yXg6NenE68NfZ2DrgXKi0EHVaEStlEpVSu1WSsUrpWIv/QjH9Nxzz9GlSxcGDhzI/v37AXjrrbfo3bs3ERER3HTTTRQWFgLGlYkPPfQQ/fv3p0OHDuclzxdffJGwsDAiIiJ4/PHHATh8+DCjR4+mV69eDBo0qGIZ1I0bN9K3b1969uzJddddx4kTJyqeJyEhgX79+tG5c2feeustoPoGBytWrODBBx/k559/ZsOGDTz22GNERkZy+PBhoqKiKrY7ePDged8LUdnR3KP8bcvfmLZpGmn5aczpN4e1N6xlUJtBkqQd2OWMqIdqrbNq40Uznn+ekn21u8ype0g3/P/1r2rvj4uLY/Xq1cTHx1NeXk5UVBS9evVi0qRJ3HPPPQA88cQTvP3228ycOROA9PR0fvzxR5KTkxk/fjw333wzX3zxBZ9++inbtm2jUaNGZGdnAzBjxgwWL15M586d2bZtG/fffz+bN29m4MCB/PrrryilWLp0KS+99BJz584FIDExkV9//ZWCggJ69uzJ2LFjL/k++/fvz/jx4xk3blzFFImvry/x8fFERkayfPly7rzzzqval6L+OVN8hiWJS1i9fzWuTq78NeKvTO8+nUaujewdmqiBBjP18cMPPzBx4kQaNTI+mGenEfbs2cMTTzzBmTNnyM/PZ9SoURWPufHGG3FyciI0NLRiJPztt99y5513VjxPs2bNyM/P5+eff+aWW26peGxJSQkAaWlp3HrrraSnp1NaWkpwcHDFNhMmTMDT0xNPT0+GDh3K9u3bK5ZhvRx33303y5cvZ968eaxZs4bt27df9nOI+qnUVMqq5FUsSVxCQVkBEztN5P7I+2nZqKW9QxOXoaaJWgNfK6U0sERr/eaFGyilZgAzAIKCgi76ZBcb+dra9OnTWb9+PREREaxYsYItW7ZU3Fd5WdSLrYliNptp0qQJ8fHxf7hv5syZzJ49m/Hjx7NlyxbmzJlTcd+Fh5pXeuh500038fTTTzNs2DB69epF8+bNr+h5RP2htebL1C95ZecrHMs/xsDWA5ndazadm3a2d2jiCtS06mOg1joKGAM8oJS69sINtNZvaq2jtdbRLVq0qNUga8O1117L+vXrKSoqIi8vj40bNwKQl5dHQEAAZWVlrFy58pLPM2LECJYvX14xl52dnY2Pjw/BwcGsXbsWMP5IEhISAKOLS+vWxnoI77zzznnP9emnn1JcXMypU6fYsmULvXv3rtF7uXAJVg8PD0aNGsVf//pXmfYQxGbEcvvnt/P3rX+nsWtjloxYwhvXvSFJug6rUaLWWh+z3GYCnwB9rBmUNURFRXHrrbcSERHBmDFjKpLis88+S9++fRkwYADdunW75POMHj2a8ePHEx0dTWRkZEWJ3cqVK3n77beJiIige/fuFb0T58yZwy233EKvXr3w8/M777nCw8MZOnQo11xzDU8++WSNG+nedtttvPzyy/Ts2ZPDhw8DMHXqVJycnBg5cmSN94moX1JzUpm1eRZ3fnUnmUWZ/GfAf1gzbg39A/vbOzRxlS65zKlSygtw0lrnWb7+BnhGa/1ldY+RZU5tLyYmhpycHJ599tlqt5HfQf2UXZzNG/FvsO7AOtyc3bg77G6mhU7D08XT3qGJy3C1y5y2Aj6xzJ+6AB9cLEkL25s4cSKHDx9m8+bN9g5F2FBxeTHv73ufpbuXUlxezM1dbua+iPvw8/S79INFnXLJRK21TgEibBCLuEKffPKJvUMQNmTWZj5P+ZyFuxaSUZDBkLZDeKTXI3Tw7WDv0Bq2E3shcx+E3VzrT23T8jyttRTV24k1OvkI29uWvo25sXPZl72P7s278/zA5+ntX7OT0MIK8jNh9zpI+AAydoOHL4SMBxe3Wn0ZmyVqDw8PTp06RfPmzSVZ25jWmlOnTuHh4WHvUMQVOnzmMPPi5rE1bSuBXoG8MOgFxgSPwUk12OV67KesGA58AQmr4eA3oE0Q2BPGvAQ9bq71JA02TNRt2rQhLS2NkydP2uolRSUeHh60adPG3mGIy5RVlMWi+EV8fPBjvFy8mN1rNreH3I67s/ulHyxqj9ZwdDskrIK9H0NxDngHQv+ZEDEFWl66Yuxq2CxRu7q6nndVnhCieoVlhbyT9A7L9yynzFTGlG5TuDf8Xpp6NLV3aA3L6SOQuMZI0Nkp4NoIQm6AiNsgeDA4OdskjAZzCbkQdYHJbOLTw5/y2q7XOFl0khHtRjArahbtfNrZO7SGozgX9m2A+FVw5EfjZ+0HwaBHIXQ8uHvbPCRJ1EI4iJ+O/cTcuLkcPH2Q8BbhzBsyj8iWl7/2i7gCZhOkbDHmnfdthPIiaNYRhj0B4bdCk4svi2FtkqiFsLP92fuZGzuXX9J/oU3jNsQMjmFku5Fy0t0WMvcZ0xqJH0JeulG1ETkFIm6HNtHgIL8DSdRC2MmJghO8Fv8anx76FG83b/7e++/c2vVW3Jxrv2pAVFKQZSmpWwXp8eDkAp1GwJgXoctocHG8E7WSqIWwsYKyApbtWca7e9/FpE3c0f0O7g67G193X3uHVn+Vl8CBLy0ldV+DuRwCImD0C0ZJXWPHW0iuMknUQthIubmcjw9+zKL4RWQXZzOm/RgeinqINt5SNmkVWsOxOIj/APZ8BMVnoLE/XHO/UVLXqu60spNELYSVaa3ZmraVeXHzSMlJIaplFK8Ne42wFmH2Dq1+OnPUUlK3Gk4dBBdPCBlnlNR1GGqzkrraJIlaCCvae2ovc2PnsiNjB+192vPK0FcY2naonCisbSX5lpK6DyD1R0BDuwEwYBaETgAPH3tHeFUkUQthBen56SzctZDPUj6jqXtT/tX3X9zc5WZcnVztHVr9YTZB6g9GvfO+DVBWCE2DYcg/IeJWaNre3hHWGknUQtSivNI8lu5eyvtJ76OU4u6wu7mrx114u9n+Iol66+QBYxGkxA8h9xi4+0L4ZGPeuW1fhympq02SqIWoBWWmMj488CGLExaTU5LDDR1vYGbPmfh7+ds7tPqhMNs4IRj/ARzfCcoZOl0HI/8DXceAa/1ukiCJWoiroLVm8++bmb9zPkdyj9DXvy+zo2cT2rzuVBQ4rPJSo5QuYRUc+ArMZdAqDEY9b5TUebeyd4Q2I4laiCuUeDKRmNgYdmXuoqNvRxYNX8Sg1oPkROHV0NoYMSesNi5KKcoGr5bQ916jasO/YVbKSKIW4jIdzTvKwp0L+TL1S5p7NOepfk8xsdNEXJzkz+mK5Rw7V1KXtR+c3aHbWIi83Sipc27Y+7Zhv3shLkNOSQ5vJr7JB8kf4Orkyn0R9zG9+3S8XL3sHVrdVFpgLICUsApS/gdoaHsN3PAKhN4Ink3sHaHDkEQtxCWUmkpZlbyKNxPfJK80j4mdJ/JA5AO0bNTS3qHVPWazsXRo/CpI+hTKCqBJOxj8D6Okrpn0fayKJGohqqG15qsjX7EgbgHH8o8xIHAAj/R6hK7Nuto7tLon66Axck5YA7lp4O4DYTdZSuquASdpKXYxNU7USilnIBY4prUeZ72QhLC/nSd2Mjd2LolZiXRp2oUl1y2hf+v+9g6rbinMNtpWxa+CY7GgnKDjMBjxtDH/XM9L6mrT5YyoZwH7gLp9LaYQF3Ek9wgL4hbw7e/f0tKzJc/0f4bxHcfjXAfXh7CL8lI49K1xQcqBr8BUCi1DYcSzxkUp3lJXfiVqlKiVUm2AscBzwGyrRiSEHZwuPs3ihMV8uP9DXJ1deTDyQf4U+icauTayd2iOT2tjXef4VbBnHRSegkZ+0PtuS0ldeL28WtCWajqiXgD8Haj2Olil1AxgBkBQkH3b1ghRUyWmElbuW8lbiW9RWF7IpM6TeCDyAfw8/ewdmuPLPW5cxp2wCk4mg7ObcZVgxO3QaTg4y7omteWSiVopNQ7I1FrHKaWGVLed1vpN4E2A6OhoXWsRCmEFZm1m02+bWLhzIekF6QxuM5hHej1CxyYd7R2aYystgOTPjUu5U7YAGtr0gXHzoftE8JQu6dZQkxH1AGC8Uup6wAPwUUq9r7WeZt3QhLCOHRk7eHnHy+zL3kdIsxCeHfAsfQP62jssx2U2w5GfjItRktZDaT74BsG1jxpVG83lPzdru2Si1lr/E/gngGVE/agkaVEXpZxJYX7cfLakbcHfy5/nBz7P2A5jcVJSGlalU4fPldTl/A5ujY0LUSJuM9Z6lpI6m5E6alHvZRVl8Ub8G3x08CM8XTx5OOphpoZMxcPFw96hOZ6i07D3E+PEYNp2QEHHoTD8Seg2Dtzk5Ko9XFai1lpvAbZYJRIhallReRHv7n2XZXuWUWoqZXLXydwXcR/NPJrZOzTHYiqDQ98Zo+f9X4CpBFp0g+ueNkrqfALtHWGDJyNqUe+YzCY2pmzk1V2vklmYyfCg4Twc9TDtfdvbOzTHoTVkJFpWqVsLBSehUXPoNR0ip0BApJTUORBJ1KJe+fn4z8yNncuB0wcI8wvj5WtfJqpVlL3Dchx5GZaSutWQuRecXKHraEtJ3XXg4mbvCEUVJFGLeuHA6QPMi53HT8d/onXj1rx87cuMaj9K1oYGKCsySuoSVsHhzaDN0Doaro+BHjdBI5kKcnSSqEWdllmYyaL4Raw/tB4vVy8ejX6UKd2m4ObcwEeGWsPvvxj1zkmfQkku+LSBgY8YJXV+ne0dobgMkqhFnVRYVsjyvct5Z+87lJnLmBYyjRnhM/B197V3aPaVnWKU0yWsgjNHwNULQicY887tBkpJXR0liVrUKeXmcj459AmLdi3iVPEpRrUfxayoWbT1bmvv0Oyn6IxxIUrCamMUjYIOg2HovyDkBnCTxgZ1nSRqUSdorfnh2A/Mi53H4ZzD9GzZk1eGvUJEiwh7h2YfpnJjvjlhlTH/bCoBvy4w/CkIvxV829g7QlGLJFELh7fv1D7mxs5lW8Y2gryDmD9kPsODhjfME4UZe4zknPghFGSCZzPodYcx7xzYU0rq6ilJ1MJhZRRksHDnQj5L+Qxfd18e7/M4k7tMxrWhrcqWn2nUOsevghO7jZK6LqOM5Nx5pJTUNQCSqIXDyS/N5+09b/Ne0ntorbmzx538Jewv+Lg1oJ4VZcWwf5Mx73zoW9AmCIwySuq6TwKv5vaOUNiQJGrhMMrMZaw7sI7FCYvJLs5mXIdxzOw5k8DGDeQSZq3h6DZjamPPJ1CSA96BMOAhY/TcQno1NlSSqIXdaa3ZfHQzC+IWkJqbSm//3rwe/Trdm3e3d2i2cTr1XEnd6d/AtRGEjDdWqQu+FqQNWIMniVrY1e6Tu4mJjWFn5k6CfYN5ddirDG4zuP6fKCzONS5ESVhlrPWMguBBcO1jEDoe3KttpiQaIEnUwi7S8tJYuHMhX6R+QTOPZjx5zZNM6jwJF6d6/JE0myDle+OkYPJnUF4MzTvBsCeNkromDT7JXLkAACAASURBVLgWXFxUPf6rEI4opySHtxLf4oPkD3BWzswIn8FdPe7Cy7UeX5RxIulcSV1+Bng0gZ7TjHnn1r2kpE5ckiRqYRNlpjJW71/N4oTF5JXmMaHTBB6MfJBWXq3sHZp1FGQZJXUJqyA9AZxcjFK6iClGaZ2Lu70jFHWIJGphVVprvj7yNQviFpCWn0a/gH78LfpvdG1WDysYykvgwJfG1Mahb8BcbqzrPPpFCLsZvKSzubgykqiF1cRnxhMTG0PCyQQ6NenE4usWM6D1AHuHVbu0hrRYS0ndR1B8BrwDoN8Dxui5ZYi9IxT1gCRqUet+z/2dBTsX8M2Rb2jh2YJn+j/D+I7jca5PZWZnfofENcYFKacOgYsnhIwzSuo6DJWSOlGrJFGLWnO6+DRLEpewJnkNrs6u3B95P3eE3kEj13rSELUkD5I2GKPn1B+Mn7UbaKzxHDIePBrQlZPCpi6ZqJVSHsBWwN2y/Tqt9b+tHZioO0pMJXyw7wPeSnyLgvICJnWexAORD+DnWQ/mZM0m+G2rkZz3bYSyQmjWAYb+n1FS17SdvSMUDUBNRtQlwDCtdb5SyhX4USn1hdb6VyvHJhycWZv54rcvWLhzIccLjnNtm2t5JOoROjXtZO/Qrt7J/edK6nKPgbuvkZgjpkDbPlJSJ2zqkolaa62BfMu3rpZ/2ppBCce3I2MHc2PnsvfUXro168bTA57mmoBr7B3W1Sk4ZZwQTFgFx3eCcjYavo56DrqMAVcPe0coGqgazVErpZyBOKATsEhrvc2qUQmHlZKTwvy4+Ww5uoVWjVrx/MDnGdthLE6qjrZ4Ki+Fg18ZJwUPfAXmMvAPg1HPQ9gt0LilvSMUomaJWmttAiKVUk2AT5RSPbTWeypvo5SaAcwACAoKqvVAhX2dKjrFGwlvsO7AOjxcPJgVNYtpIdPwcKmDo0ytjRFz/CrYsw6KTkPjVtD3XmNqw7+HvSMU4jyXVfWhtT6jlPoeGA3sueC+N4E3AaKjo2VqpJ4oKi/i/aT3eXvP2xSXF3NLl1u4L+I+mnvWwfWQc9LOldRlHQAXD+g21kjOHYaCsxRBiSujtebYmSJO5JbQq13TWn/+mlR9tADKLEnaExgBvFjrkQiHYtZmNh7eyKu7XuVE4QmGth3KI70eIdg32N6hXZ6SfKNaI2GVUb2BhqB+cMNC6H4jeDTwruXishWXmTh4Ip996bkkpeeyz/Ivt7ic5l5uxD5xXa2v/liTIUQA8I5lntoJ+FBr/VmtRiEcyq/pvzI3di7J2cn0aN6DFwa9QLR/tL3Dqjmz2ahzTlhl1D2XFUCTdjD4HxBxq1FeJ0QNnMwrOS8Z70vP5fDJAkxmY9KgkZszXf29uSEikJAAH0ICrFNLX5Oqj0Sgp1VeXTiUQ6cPMS9uHj8c+4FAr0BeHPQio4NH150ThVkHIf4DS0ldGrj7QNhNxtRGUD8pqRPVKjeZSckqMEbJx8+OlPPIyi+p2CbQ14OQAB9GdfevSMrtmjXCycn6nyuZlBOcLDzJovhFfHLoE7xcvPhbr78xJWQK7s51YIW3wuxzJXXH4kA5QcfhMOJpY/7Z1dPeEQoHk1NYxr4MIyHvS89lX0YuB07kU1puBsDN2YnOrRozpGsLQi0JOSTAmyaN7NdEWBJ1A1ZYVsg7e99h+d7llJnLuL3b7dwbfi9NPJrYO7SLKy81VqeL/+BcSV3L7jDyP0ZJnbe/vSMUDsBs1vyeXXjBXHIex84UVWzj19iNkAAfpvdvX5GUO7TwwtXZsY4iJVE3QCazifWH1rMofhEni04yot0IHo56mCAfBy6r1BqO7zIqNvasg8JT4NUC+swwFkLyD5OpjQassLSc5Iy8innkpOO57M/Io6DUBICTgo4tGtOrXVOmXdOOkABvQgN9aOldN8pLJVE3IFprfjr+E3Nj53LozCEiWkQwb8g8IltG2ju06uUeP1dSdzIZnN2g6/UQeTt0HAbOrvaOUNiQ1pr0nOJKJ/fySErPJfVUAdpSFOzt7kJIgA+3RLclJMCbkAAfurTyxsO17q5oKIm6gUjOTmZu7Fx+Tf+Vtt5tmTt4LiPajXDMJrKlBZD8uTG1kbIF0NC2L4ybD90ngmft16kKx1NSbuJQZr5lLjmvYj75TGFZxTZBzRoREuDNhMjAiqmLNk09HfNzfRUkUddzGQUZvLbrNTYc3oCPuw//6P0Pbu16K66ONhI1m41u3AmrjO7cpfngG2R05Y64DZp3tHeEwopO5ZecS8aWOeVDmfmUW8rgPFyd6Orvw5ge/hUJuau/N94eDvY5thJJ1PVUQVkBb+9+m/eS3sOkTdzR/Q7uDrsbX3cHu8Aj6xAkroaENZDzO7g1htAbIXIKBPUHJ8c6qSOujsms+S0rn6T08+eTM/POlcH5+3gQEuDNsG4tCQnwITTQh/bNvXC2QRmco5JEXc+Um8v5+ODHLIpfRHZxNmOCxzArahatG7e2d2jnFJ2GPR8b885p242Sug5DYPhTRkmdWz1pNNDA5RaXkXzBKHl/Rh4lljI4V2dFp5beDOzsV6kMzodmXvYrg3NUkqjrCa01/0v7H/Pi5vFbzm/0atWLRcMX0cPPQRYYMpXBoW+NqY39X4CpFFqEwIhnjJI6n0B7RyiukNaao9lF513Bl5SeS9rpc2VwTRu5EhLgw5+uaVeRkDu1bIybixwx1YQk6npg76m9zI2dy46MHbT3ac8rQ19haNuh9j+hojVkJBqr1O1eC4VZ0Kg5RN9lXC0YECEldXVMUamJ/Sfyzrukel96Hvkl5YDx6wz28yKibROm9AmqGCm38nG3/+exDpNEXYcdzz/Owl0L+Tzlc5q6N+X/+v4fN3W5CVcnO59gyU2H3R8aUxuZSUZJXZfRRkldp+ukpK4O0FpzIrfkDwsP/ZZVgOX8Ho3dXejm783Enq0rrt7r6u9NIzdJK7VN9mgdlFuay9LdS1mZtBKlFHeH3c1dPe7C283bfkGVFVUqqfsetBna9Iax84ySukbN7BebuKjScjOHMvPPjZAzjFFydkFpxTZtmnoSEuDD2PBAQi21yW2b2madCyGJuk4pM5Xx4YEPWZywmJySHG7oeAMze87E38tOl0ybzfD7L+dK6kpywbctDJxtTG341YPeifXM6YLSilHy2YWHDmXmUWYyhsnuLk509fdmREiriotFugX44OspR0H2JIm6DtBa8+3v37IgbgG/5/1OX/++/C36b4Q0D7FPQNkpxrRGwmo4c8RSUjfBqHduN1BK6hyAyaxJPVVwXgncvvQ8MnKLK7Zp6e1OSIAPg7u0MC6pDvAh2M8LFwdb50JIonZ4CScTiNkRQ/zJeDr6dmTR8EUMaj3I9idmis5A0nrjxODRXwFllNQN/T8IGQduXraNR1TILyknuaLawjjRtz8jj6IyY50LFydFxxaN6dexecUoOSTAB7/GdWB1RAFIonZYR/OO8srOV/gq9Sv8PP34d79/c2OnG3FxsuGvzFQOhzdDwgeQvAlMJeDXFa6bA2GTwdeBarMbAK01aaeLKiotzs4nHzlVWLGNr6crIQHeTOkTVJGUO7dqjLtL3V3nQkiidjg5JTksSVzCquRVuDq58teIvzK9+3QaudrwIpCM3ca0RuKHUJAJns2g1x3GvHNgTymps4HiMhMHKsrgjIWHki3tnsD4FbRv7kX3QB9u6dWmYpQc4OshZXD1kCRqB1FqKmVV8iqWJC6hoKyAGzvdyAORD9CyUUvbBJB3wqh1TlgNJ3aDkyt0GWUpqRsBLnK1mLVk5hUbyfj4uTK4lKzz2z11q9TuKTTQh66tvPFylz/fhkJ+03amtebL1C95ZecrHMs/xoDAAcyOnk2Xpl2s/+JlxbD/cyM5H/oOtAkCo+D6GOhxk5TU1bIyk5mUkwXnXb23Lz2XrPxzZXBn2z2N7mH7dk/CcUmitqO4E3HMjZ3L7qzddGnahSUjltA/sL91X1RrOLrNqHfeux5KcsCnNQyYZVRttOhq3ddvIHIKy85vipqRy4GMfEpNF7Z7aukw7Z6E45JEbQepOanMj5vP5qObadmoJc8OeJYbOtyAs5MVT/icTjVWqEtYBad/A1cvCB1vJOf2g8Car12PXVa7pwGO3e5JOK5LJmqlVFvgXaAVoIE3tdavWDuw+ii7OJvFCYtZu38tbs5uzOw5kz+F/glPFys1YC3ONUrqElYbaz2jIHgQDP4HhNwA7o2t87r11Nl2T5Xnkiu3e3J2UnTw86JXu6b8qV+7ilFyXWn3JBxXTUbU5cDftNY7lVLeQJxS6hutdZKVY6s3isuLeX/f+7y9+22Kyou4ucvN3BdxH36efrX/YmYTHP7eGDknfwblxdC8Ewx7EsJvhSZta/8165nK7Z6Sjp+7pPq8dk8e57d7Cg3wpXOrxnW63ZNwXJdM1FrrdCDd8nWeUmof0BqQRH0JZm3m85TPWbhrIRkFGQxpO4RHej1CB98Otf9iJ5KMeufEtZCfAR5NoOc0o6SudS8pqatGSbmJgyfyK5XB5bAvPY+covPbPYUG+HBjZOuK2uT62O5JOK7LmqNWSrUHegLbqrhvBjADICjIgbtZ28i29G3MjZ3Lvux9hDYP5fmBz9Pbv3ftvkj+SaMjd/wHxnKiTi7QeaSRnLuMAhe58qyyrPyS85uiHs/l8Mk/tnu6PqxhtnsSjkvps8dyl9pQqcbA/4DntNYfX2zb6OhoHRsbWwvh1T2HzxxmXtw8tqZtJcArgFlRsxgTPAYnVUsnjsqK4cCXxtTGwW+MkrqASKPeucdN4GWF6ZQ6ptxkJvVUAXsrN0VNr7rd09kSOGn3JOxNKRWntY6u6r4ajaiVUq7AR8DKSyXphiqrKIvX41/no4Mf4eXixSO9HmFqyFTcnWthVKs1pO0wkvOej6A4B7wDoP+Dxui5pZ0WZ3IAl9vuKdSyGpy0exJ1SU2qPhTwNrBPaz3P+iHVLYVlhbyb9C7L9iyjzFTGbV1v476I+2jq0fTqn/zM7+dK6rIPg4unUa0ROQWCBzeokroL2z2dva3c7qmZlxshAd4V7Z5CA33o2ELaPYm6ryYj6gHAn4DdSql4y8/+pbXeZL2wHJ/JbGLD4Q28tus1MosyGdFuBLOiZtHOp93VPXFJnrG2c8JqSP3B+Fn7QTBotrGUqLsdmwPYyIXtnpKO55Kcca7dk5Ol3VNkpXZPoYE+tPSWdk+ifqpJ1cePgHz6K/n52M/ExMVw8PRBwv3CiRkSQ8+WPa/8Cc0m+O1/xhKi+zZCeRE06whDn4DwydD0KpO/g6qq3VNSei6pVbR7mhTVumI+uWsrbzzdGs7RhBByZeJl2J+9n3lx8/j5+M+0btyamMExjGw38spHcZnJxrRG4oeQdxw8fI0rBSNvN9pY1aPRYVXtnpKO53K68FwZ3Nl2T+Ms7Z5CA3xp09RT1rkQDZ4k6ho4UXCCRfGLWH9oPd5u3jwW/Ri3dbsNN+crOCFVkGWcEIz/ANLjQTlD5xEw+r9GA1jXun8VW7al3dO5kXLV7Z5GhvpLuychakAS9UUUlBWwfM9y3tn7DiZt4s+hf+ae8Hvwdfe9vCcqL4EDXxnzzge/AnM5+IfDqP9C2C3QuIV13oCVnW33VPmSamn3JETtk0RdhXJzOZ8c+oRFuxZxqvgUo9uP5qGoh2jrfRmXX2sNx+LOldQVnYbGreCavxolda26W+8NWMH57Z6Mlk8HLmj31KmltHsSwhokUVeiteaHYz8wN3YuKTkpRLWMYuGwhYS3CK/5k5w5ColrjNHzqYPg4gHdxhnJucMQcHbsXV5Vu6ek9Fx+zz7X7qlJI1dC/H2k3ZMQNuLYWcOGkk4lMS92HtsyttHOpx0LhixgWNCwmp0oLMmHfRuM0fNvPwAagvrDgIeMkjqPy5wqsZGatnsKa+3L5Ghp9ySEvTT4RJ2en86ru15lY8pGmrg34fE+jzO562RcnS5xYstsMuqc41cZSbqsEJq2hyGPG6vUNQu2Sfw1lZlXbJlLPlefXF27p9BAIyF38/emkVuD/4gIYXcN9q8wrzSPt3e/zXtJ7wFwV4+7uDvsbrzdLnFByckDllXqPoTcY+DuY5wQjLwd2va1e0nd2XZPZ1eBO5uUK7d7at3Ek5AAb8ZUavcUJO2ehHBYDS5Rl5nLWHdgHW/Ev8HpktOM6zCOmT1nEtg4sPoHFWafK6k7vtMoqes0HEY+C12vB1crLfx/CZXbPZ29PXji/HZPXfwbM7Rry3OLDwX44NtIyuCEqEsaTKLWWrP56GYWxC0gNTeVPv59mB09m+7Nq6m+KC+Fg18b884HvgJzGbTqASOfM0bQ3q1sFrvZrDliafdU+bLq4znnyuCk3ZMQ9VeDSNSJJxOZGzuXnZk76eDbgUXDFzGo9aA/nhDT2hgxJ6yG3eugKBu8WkCfGcZCSP5hVo+1qnZPyRl5FF7Q7ql3cLOKUbK0exKifqvXiTotL42FOxfyReoXNPNoxpPXPMmkzpNwcbrgbeccO1dSl7UfnN2h2/VGSV3H4VYpqavc7qnyFXxVtXuaHN22YpQs7Z6EaHjqZaLOKcnhrcS3+CD5A5yVM/eG38udPe7Ey9Xr3EalBbDvM+PEYMr/AA1tr4FxC6D7RPBsUmvxVG73VLlTdeV2T+2aNyLE32j3ZFRdeNO6ibR7EkLUs0RdaipldfJqliQuIa80jxs73cgDkQ/Qyssyn2w2w5EfjZFz0qdQmg9NgmDw342SuuYdrzqGyu2ezpbDVW735OnqTFd/b64PCzAWHgr0oau/D43d69WvQghRi+pFdtBa8/WRr1kQt4C0/DT6B/Zndq/ZdG3W1dgg65Bllbo1kHMU3LyNUXPEFAjqB06Xf8Kt3GTmt6yCiimLsyPlkxe0ewoN9OG60HNVF9LuSQhxuep8ot6VuYuY2BgSTybSuWlnFl+3mAGtBxgldTuWGqPntB2gnKDjMLhujlFS59aoxq+RU1RWsc7F2aR84MQf2z0NknZPQggrqLOJ+kjuERbELeDb37+lhWcLnun/DOPbj8E55XtY8yejAaypFFqGwohnjZI6n4CLPqfZrDl6utAyl3yu8uLYGWn3JISwnzqXqE8Xn2ZJ4hLWJK/B1dmVByIf4M/NImm0Zz188igUZkEjP+h9t7EIv394lVcLFpWaSM44/5Lqqto99Qxqwu19pd2TEMJ+6kyiLjGVsHLfSpYmLqWgvICb2o3hfnzx++kdyPwHOLtB1zHGvHOn68DZuPpOa82JnOKKS6rPziX/lnWuDK6xuwshAdLuSQjhmBw+UZu1mU2/bWLhzoWkF6RzrU9nZueV0HHLEtBmaNMHxs2H7hMpdfU12j3FnzivFK5yu6e2zTwJ8ffhhvBAQgJ86B7oQ5umUgYnhHBcl0zUSqllwDggU2vdw/ohnbMjYwcxO2JIyk4ixLkxz57Mo+9v34FvW4queZikFtezq6A5SSm57Ptpzx/aPXXz92ZU93MLD3UL8MbHQ9a5EELULTUZUa8AXgPetW4o56ScSWH+r/9hy4kd+Jvh+VNZjCrOIrnpMF7wGsKn2e1J/74UyAQyaentTmigD0O6trAsPORN++bS7kkIUT9cMlFrrbcqpdpbPxQ4krGfRVuf4qvCJBppMw+dyaVTThDrS8fxd3M0ZYWedGrZmGs6+VRcUh0S4E1zafckhKjHHGaOOjvnGFM2TaLISTEqV9M0px+7/G4kvVMHBgZ4MyPQh04tpd2TEKLhqbVErZSaAcwACAoKuuzHN/NtzY0e/ekWMJToyBsJkHUuhBACAKXP1qhdbCNj6uOzmp5MjI6O1rGxsVcXmRBCNCBKqTitdXRV98nZNiGEcHCXTNRKqVXAL0BXpVSaUuov1g9LCCHEWTWp+phii0CEEEJUTaY+hBDCwUmiFkIIByeJWgghHJwkaiGEcHCSqIUQwsFJohZCCAcniVoIIRycJGohhHBwkqiFEMLBSaIWQggHJ4laCCEcnCRqIYS4StpsxlxYiCknxyrP7zAdXoQQojZpsxldXIy5uLia2xJ0cRHm4hLMxUXo4hJ0STHmouI/3JpLitFV3pagi4rQpaUAuLRoQecfttb6e5FELYSwGV1ebiTIqhJitQm1GF1cUv39lmR54a0uK7uyIF1dcXJ3R3l64OTugfJwx8nDE+XhjrO3D6pFi4rvndw9cPL0QFlunXx8aneHWUiiFqKBq0ieltHl5d6eHY1WjErPJtE/jEZL4GqSp8e5pOnk4W4kRw8PnH18cGrVElUpqVZOnhe99XBHnX2+s7cujpcWHS8iIQS6rOyih+wXJscLD93PO0Svcvtzo9ErTZ7KzQ3l4WFJoB7GKNTyvXOzpsZotGJU6nFeoj3/ttL9Z0emlp9VJFMHTJ621LDfvRA1pLWGsjLMJSWYi4rQlW7PJtHzEmoN5jUvdovJdEVxKjc3lKfn+Yfullun5s1wrcko82KjzbPP7e6Ocnau5b0sqiOJWtRZWmt0WZmR3Ko6NK9yHvRih/IXmSe9muR5drR5NslVGoU6t2hx/qi0quRY+VC/qqRaaTSrnKSQqz6SRC1qldYaXVpadbKr4mz6pc+qX/xEElpfUZznJ8fzk52zt3fVo9ILt690e+5Q3R0nT8/zbpVStbyXRUMjiboB0Fqfd6j+h9tqz7JXN695kUP4K02eSp1LflXMa7o2aXL+vGblQ3rL6PLC+c/zDtUrjWYleYq6RhK1nWizufokeV4yrWIUetHa0Kqf74o4OVU/imzkiXOzZlUfmlccsntUeaLoD/Ognp4oV1dJnkJUo0aJWik1GngFcAaWaq1fsGpUdlJ9gXz1JUkXPZS/yKj0ipOns3PVh+yenjh5eeHs53dBDeiFSbbSofklDuWR5CmEQ7hkolZKOQOLgBFAGrBDKbVBa51k7eAAtMn0h+RZs9GkDQvkL0yeleY1nRt7GwXyVRyqX/SQ/cJD97PP7epauztYCOHwajKi7gMc0lqnACilVgMTgFpP1L9NuglTXt55SfWqri6qQYH8eYfgfzh0r+Zs+4WjWUmeQggrqkmibg0crfR9GtD3wo2UUjOAGQBBQUFXFIxbx44AF5QmXfxs+x/PukuBvBCifqm1bKa1fhN4EyA6OvqKaqZav/xSbYUjhBD1Rk2q448BbSt938byMyGEEDZQk0S9A+islApWSrkBtwEbrBuWEEKIsy459aG1LldKPQh8hVGet0xrvdfqkQkhhABqOEettd4EbLJyLEIIIaogK7gIIYSDk0QthBAOThK1EEI4OEnUQgjh4JS+wvV8L/qkSp0Ejlzhw/2ArFoMp7ZJfFdH4rs6Et/VceT42mmtW1R1h1US9dVQSsVqraPtHUd1JL6rI/FdHYnv6jh6fNWRqQ8hhHBwkqiFEMLBOWKiftPeAVyCxHd1JL6rI/FdHUePr0oON0cthBDifI44ohZCCFGJJGohhHBwdkvUSqnRSqn9SqlDSqnHq7jfXSm1xnL/NqVUexvG1lYp9b1SKkkptVcpNauKbYYopXKUUvGWf0/ZKj7L66cqpXZbXju2ivuVUmqhZf8lKqWibBhb10r7JV4plauUeviCbWy6/5RSy5RSmUqpPZV+1kwp9Y1S6qDltmk1j73Dss1BpdQdNozvZaVUsuX394lSqkk1j73oZ8GK8c1RSh2r9Du8vprHXvRv3YrxrakUW6pSKr6ax1p9/101rbXN/2Esl3oY6AC4AQlA6AXb3A8stnx9G7DGhvEFAFGWr72BA1XENwT4zB77z/L6qYDfRe6/HvgCUMA1wDY7/q4zMIr57bb/gGuBKGBPpZ+9BDxu+fpx4MUqHtcMSLHcNrV83dRG8Y0EXCxfv1hVfDX5LFgxvjnAozX4/V/0b91a8V1w/1zgKXvtv6v9Z68RdUXDXK11KXC2YW5lE4B3LF+vA4YrpZQtgtNap2utd1q+zgP2YfSOrEsmAO9qw69AE6VUgB3iGA4c1lpf6ZWqtUJrvRXIvuDHlT9j7wA3VvHQUcA3WutsrfVp4BtgtC3i01p/rbUut3z7K0Z3JbuoZv/VRE3+1q/axeKz5I3JwKrafl1bsVeirqph7oWJsGIby4c1B2huk+gqsUy59AS2VXF3P6VUglLqC6VUd5sGBhr4WikVZ2ksfKGa7GNbuI3q/0Dsuf8AWmmt0y1fZwCtqtjGUfbjXRhHSFW51GfBmh60TM0sq2bqyBH23yDghNb6YDX323P/1YicTLwIpVRj4CPgYa117gV378Q4nI8AXgXW2zi8gVrrKGAM8IBS6lobv/4lWVq3jQfWVnG3vfffebRxDOyQtapKqf8DyoGV1Wxir8/CG0BHIBJIx5hecERTuPho2uH/luyVqGvSMLdiG6WUC+ALnLJJdMZrumIk6ZVa648vvF9rnau1zrd8vQlwVUr52So+rfUxy20m8AnGIWZljtCUeAywU2t94sI77L3/LE6cnQ6y3GZWsY1d96NSajowDphq+c/kD2rwWbAKrfUJrbVJa20G3qrmde29/1yAScCa6rax1/67HPZK1DVpmLsBOHuG/WZgc3Uf1NpmmdN6G9intZ5XzTb+Z+fMlVJ9MPalTf4jUUp5KaW8z36NcdJpzwWbbQD+bKn+uAbIqXSYbyvVjmTsuf8qqfwZuwP4tIptvgJGKqWaWg7tR1p+ZnVKqdHA34HxWuvCarapyWfBWvFVPucxsZrXtXdz7OuAZK11WlV32nP/XRZ7ncXEqEo4gHFG+P8sP3sG40MJ4IFxyHwI2A50sGFsAzEOgxOBeMu/64H7gPss2zwI7MU4i/0r0N+G8XWwvG6CJYaz+69yfApYZNm/u4FoG/9+vTASr2+ln9lt/2H8h5EOlGHMk/4F45zHd8BB4FugmWXbaGBppcfeZfkcHgLutGF8hzDmd89+Bs9WQQUCmy72WbBRfO9ZPluJGMk34ML46MeyrwAAAFBJREFULN//4W/dFvFZfr7i7Geu0rY2339X+08uIRdCCAcnJxOFEMLBSaIWQggHJ4laCCEcnCRqIYRwcJKohRDCwUmiFkIIByeJWgghHNz/A0TxBuUBdKdhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_iterations = range(20)\n",
    "Y_margins = [[], [], [], []]\n",
    "\n",
    "list_margins = [(1,0.1), (1,0.2), (1,0.3), (0.01,0.02)]\n",
    "for i in range(20) :\n",
    "    for j in range(4) :\n",
    "        Y_margins[j].append(list_margins[j][0] + i * list_margins[j][1])\n",
    "        \n",
    "labels = [\"tempo\", \"loudness\", \"hotness\", \"danceability\"]\n",
    "for i in range(4) :\n",
    "    plt.plot(X_iterations, Y_margins[i], label = labels[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar songs following the model 1:\n",
      " * Little Game - Double A\n",
      " * Can't Get Enough Of Your Love Babe - Barry White (1988)\n",
      " * I Love You And You Love Me - Andy Russell\n",
      " * Party In The Burbs - John Brown\n",
      " * Almost Like Being In Love - US Army Field Band Jazz Ambassadors\n",
      " * Reten - Bostich_ Fussible\n",
      " * Look Around - Moonbeam\n",
      " * Frustrate - Flotsam and Jetsam (2001)\n",
      " * Teenage Dad On His Estate - Morrissey (2004)\n",
      " * El nio de la calle - Alfredo Gutirrez\n"
     ]
    }
   ],
   "source": [
    "songs_similar_model1 = similar_model1(user_song, 10, margins)\n",
    "print(\"Similar songs following the model 1:\".format(margin))\n",
    "for song in songs_similar_model1.collect() : \n",
    "    print(\" * \", end=\"\")\n",
    "    print(song_str(song))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "|                id|                name|            location|   hotness|               terms|     similar_artists|\n",
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "|ARM41VP1187FB52F30|     The Five Satins|       New Haven, CT|0.42246866|oo-wop,soft rock,...|R5MJOG1187FB382DF...|\n",
      "|AR4DHNI1187FB36871|       Alfred Newman|       New Haven, CT|0.31283298|azz,soundtrack,ea...|RKU15L1187B99198D...|\n",
      "|ARRH7LQ1187B9B4A77|Michael Allen Har...|       United States|0.35435557|asy listening,coo...|R5N6X41187B988BFF...|\n",
      "|ARYWF8L1187B98A016|              Zumjay|                null| 0.3239861|ancehall,reggae,j...|RX9I2Y1187FB4B5EB...|\n",
      "|ARV2MS01187FB39026|          Les Baxter|         Detroit, MI|0.41340813|asy listening,lat...|R0O9WU1187FB55E83...|\n",
      "|ARPN2BY1187B999693|       Mind.In.A.Box|                null|0.43679497|uturepop,dark wav...|R8YYNB1187B9A4BB3...|\n",
      "|ARA04401187B991E6E|JOSEF LOCKE & ORC...|Londonderry, Nort...| 0.2859012|olk rock,folk,cou...|RKLWV31187FB4881F...|\n",
      "|ARHJMXS1187FB464C8|   Between The Trees|         Orlando, FL| 0.4915116|iano rock,emo,mod...|RYK3341187B98BE06...|\n",
      "|AR6HPLV1187FB4A1BC|      Sample Rippers|                null| 0.3675651|ard trance,hardst...|RIMMYT1269FCD4C88...|\n",
      "|ARW24PI1187B9A6126|               Jewel|          Payson, UT|0.50952834|op rock,rock,pop,...|RH5FJJ1187FB3F787...|\n",
      "|ARW93361187B99B135|       Victor Garber|                null|0.29806226|how tunes,easy li...|RJPDKW12454A4766D...|\n",
      "|ARK8SPO1187FB3A1E8|Solitary Experiments|                null|0.40351522|lectro,futurepop,...|RQCL0E1187FB38365...|\n",
      "|ARPCNNQ1187B9992CF|         The Cootees|                null|0.32306805|op punk,trip hop,...|R4J8B41187FB3D170...|\n",
      "|ARM5PEE1187B9AEF3D|           DISMEMBER|  Sweden (Stockholm)|0.46423903|eavy metal,death ...|RWTYWF1187B9AF87C...|\n",
      "|ARTXQGD11EDCAC6814|     Cristian Castro|                null| 0.4368712|os angeles,pop,la...|RKKWTD12086C16221...|\n",
      "|ARF2EHS1187B994F4E|       Kings Of Leon|Nashville, Tennessee|0.78880596|outhern rock,alte...|R3KUCG1187B9A0BEA...|\n",
      "|AR1WYY01187B98978E|          Karpe Diem|                null| 0.4473385|op rap,hip hop,co...|RB3BJV1187FB4C3D6...|\n",
      "|ARZDUML1187B9AD101|     SKOLD vs. KMFDM|                null|0.35658035|eavy metal,indust...|R3NHIA1187B9AC99B...|\n",
      "|AR2ZXVY1187B998634|        Chantal Goya|     Saigon, Vietnam|0.47963285|hanson,europop,po...|RQD13K1187B98E441...|\n",
      "|ARIDYOQ11E2835C995|  Slavic Soul Party!|                null| 0.4082355|lezmer,polka,bras...|RZSL1M1187B99BC1E...|\n",
      "+------------------+--------------------+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_artists.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Little Game'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_similar_model1[0][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "terms = songs_similar_model1.join(df_artists, df_songs.artist_id == df_artists.id)\\\n",
    "        .select(df_artists.location, df_artists.hotness, df_artists.terms)\\\n",
    "        .collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(location=None, hotness=0.0, terms='ortec,los angeles,electronica,psychedelic,funk,disco,techno,world music,dance,mexican,minimal,heavy,up beat,electronic,groove,european,traditional,mexico,eclectic,fusion,70s,world,funky,gypsy,cover'),\n",
       " Row(location='Galveston, TX', hotness=0.5418768525123596, terms='uiet storm,disco,motown,soul,urban,r&b,funk,beat,smooth soul,oldies,soft rock,neo soul,northern soul,easy listening,ballad,blues,classic rock,male vocalist,downtempo,jazz,rock,soundtrack,hip hop,rap,singer-songwriter,70s,pop,sexy,funky,80s,classic,romantic,american,mellow,female vocalist,90s,lounge,indie,alternative,electronic'),\n",
       " Row(location=None, hotness=0.46209636330604553, terms='rogressive house,tech house,progressive trance,techno,tribal house,trance,electronic,electro,vocal house,hard trance,minimal,house,downtempo,germany,russia,nederland,intelligent dance music,dance,chill-out,electronica,male vocalist,female vocalist,ambient,spain,united states,breakbeat,progressive,melodic,belgium,party music,experimental,industrial,vocal trance,minimal techno,dj,calming,electro house,portugal,microhouse,french,malaysia,minimal tech house,neotrance'),\n",
       " Row(location=None, hotness=0.4063268005847931, terms='peed metal,heavy metal,rock,thrash metal,power metal,disco,hard rock,progressive metal,classic rock,united states,alternative rock,indie rock,electronic,metal,pop,spoken word,germany,punk,80s,synthpop,industrial,american,progressive rock,emotional,nederland,trash metal,european,true metal,french,speed,arizona,guitar god,old school thrash metal,technical thrash metal,funk soul,progressive thrash metal'),\n",
       " Row(location=None, hotness=0.279255747795105, terms='ouisiana blues,merengue,jump blues,east coast blues,salsa,vallenato,bolero,blues,jazz,rock,swing,folk,latin,world,country,funk soul'),\n",
       " Row(location=None, hotness=0.28199511766433716, terms='orld,jazz,latin,spanish,swing,crooner,old timey,traditional pop,male vocalist,boleros,world reggae'),\n",
       " Row(location='North Carolina', hotness=0.38718193769454956, terms='ard trance,hard house,country blues,happy hardcore,ccm,disco,reggae,intelligent dance music,hip hop,rap,country,americana,electronic,trance,electro,hardcore,rock,synthpop,alternative,indie,experimental,spain,abstract,north carolina,lyrical,entity,alternative rock'),\n",
       " Row(location='Manchester, England', hotness=0.5577667951583862, terms='op rock,rock,british pop,indie,alternative,england,rockabilly,alternative rock,guitar,vocal,solo,emo,political,pop,beautiful,romantic,rap,punk,lyrics,indie rock,funny,instrumental,heavy,song writer,epic,dark,cover,modern,up beat,electronic,acoustic,melodic,sad,party music,melancholia,piano,ambient,soul,poetry'),\n",
       " Row(location=None, hotness=0.0, terms='azz,big band'),\n",
       " Row(location='Texas', hotness=0.3516758382320404, terms='ungle music,rap,electronica,hip hop,electronic,drum and bass,house,electro house,ambient,urban,texas,party music,r&b')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Releasing the resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
